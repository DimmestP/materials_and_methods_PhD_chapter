%
% Sample SBC book chapter
%
% This is a public-domain file.
%
% Charset: ISO8859-1 (latin-1) áéíóúç
%
\documentclass{SBCbookchapter}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil,english]{babel}
\usepackage{graphicx}
\usepackage{array}

\setcounter{chapter}{2}

\author{Sam Haynes}
\title{Materials and Methods}

\begin{document}
\maketitle

\begin{abstract}
This chapter contains the software development, microbiology and statistical methods used to complete my research. For the development of tidyqpcr I discussion the techniques of open software development and effective evaluation of user experience. I also outline the process of creating reproducible and quality controlled RNA-seq analysis. I describe the qualitative statistical methods used across my PhD research include linear modelling, Gaussian Processes and developing novel Bayesian models to normalised RNA-seq datasets. Finally, I outline the experimental assays planned and executed with the Wallace lab specifically for the completion of my research. 

\end{abstract}

\section{Software Development}

The open software development strategies developed by the mozzula open leaders program were the basis of all development in this thesis. Similar to the agile practice of software development with pair programming, focus on the minimal viable product and regular feedback from users. Focus on a project roadmap to separate functionality into core and improvements. The program emphasises developing code to support a diverse community and contributors. Outlining the purpose of the software, current functionality and how to contribute. User profiles were created to understand who the users were and what their skill levels would be. Creating a code of conduct. Using GitHub's native functions to establish collaborations (template pull requests, transparent decision making with issues tickets and actions to automate checking any new pull requests). Unit testing as a requirement to quality control. Integrating already available tools. Submitting software for code review by open initiatives and finding journal for submission.

\subsection{User interviews}
We explored how users interact with tidyqpcr by conducting 7 semi-structured, exploratory interviews. These interviews where conducted over zoom with the video recorded and transcripts created by zoom's proprietary software over a period between 45 and 90 minutes. Software developers are often unaware of their own unconscious knowledge which may create a barrier for users to engage with user. Also, language differences between disciplines and non-native speakers can create obstacles.  The interview, outline in appendix A, was in two halfs: part one explored the users experience with qPCR assay, analysis and coding, part two consisted of a series of tasks based on the vignettes. The interviewees consisted of member of the lab who are known to have conducted qPCR previously or are intending to conduct research in the near future as well as other academic colleagues known for conducted qPCR experiments. The questionnaire section explored whether users were aware of the MIQE-guideline and if they currently executed any QC measures. We also wanted to know the typical experiments users wanted to conduct: qPCR assay, machine, No of wells. Finally, we wanted to explore what software users currently used to analyse their results and if they were interested in learning R based analysis. The task-based section of the interview focused on three main themes of tidyqpcr: block based plate planning, tidyverse based API and conducting reproducible analysis.

\begin{center}
\begin{tabular}{|| m{4cm} | m{4.4cm} | m{4.5cm} ||} 
 \hline
 \textbf{\large Position} & \textbf{\large Coding Experience} & \textbf{\large qPCR Experience} \\ [0.5ex] 
 \hline
 Undergraduate student & Novice Python user & No prior experience\\ 
 \hline
 Senior post-doctoral research assistant. & Intermediate R user & Conducting qPCR for >10 years \\
 \hline
 Research assistant & Intermediate R user & Conducted 1000's of qPCR experiments\\
 \hline
 PhD student & Confident R user & Conducted several qPCR experiments \\
 \hline
 PhD student & Novice R user & Conducted several qPCR experiments\\
 \hline
 PhD student & Intermediate Python user & Conducted several qPCR experiments\\
 \hline
\end{tabular}
\end{center}

User interviews for tidyqpcr were conducted and recorded using zoom. The audio was then transcribed using otter.io rather than the default zoom transcriber as otter.io allows you to introduce specialist vocabulary (such as tidyqpcr, taqman, ect) to aid accuracy. Once the transcripts were available they were split into two halves: the semi-structured interview and the user task. The semi-structured interview and the user task sections were combined for all the user interviews. Each combined section was then analysed separately to create two text clouds.  The text mining R packages tm and pluralize were used to preprocess the transcripts and extract frequently used words. The text was pre-processed by removing whitespace, numbers and common words; converting all plural nouns to singular; and changing all letters to lower case. The frequency of each word was then counted and any generic words  regularly occurring within the transcript were removed; for example that, like and thing. Finally, the word frequency matrix was used to create the text cloud with the R package wordcloud.

\section{RNA-seq Analysis Pipelines}

Sequence reads were checked for call quality, repetition and GC content using FASTQC. Each QuantSeq sample was ran over four sequencing lanes and reads were concatenated together. 5PSeq reads contained UMIs due to the additional PCR amplification step and they were separated using UMItools. Illumina adapters and reads with low call quality were removed with Cutadapt. HiSat-2 read aligner was used to align reads from both assays. Both provide paired end reads but with different strandedness. QuantSeq was postive stranded read1 and 5PSeq contained negative stranded read1. The sacCer3 (R64-2) genome build was used for alignment taken from the Saccharomyces Genome Database with the addition of the plasmid sequence. The quality of the alignment was checked by compared the fraction of unambiguously aligned pairs of reads using MultiQC. The gtf was custom made to include the 3'UTRs as detected by pelchena et al. Once reads were aligned the 5PSeq pipeline used UMItools to detect duplicates. The reads mapped to each 3'UTR were counted using featureCounts. Samtools and Bedtools were used throughout to manipulate the alignment files. The analysis of 5PSeq and QuantSeq was conducted using the same NextFlow pipeline was different user defined arguments. A custom script function extracted reads mapped to the 3'UTRs of the constructs of interest.

\section{Linear Regression}

\section{Gaussian Processes}
Gaussian processes are a Bayesian method developed for analysing time series data. Time series data is structured differently to other continuous data types as it often has strong autocorrelation between neighbouring points and repeating cycles. Standard linear regression models often struggle to model this behaviour (although circular patterns can be learnt from finite linear combination of sin/cos functions). They are the projection of Gaussian distribution into infinite dimensions. By defining the covariance function, which relates the value of each point to every other point, can a various attributes to the fitted model. For example, if the fitted line must be continuous and differentiable then the covariance functions must be similarly defined. Similar to a finite multi-dimensional Gaussian it is fully defined by two parameters:  the mean function and the covariance function. As it is a Bayesian method it also create an error at in the expected value at any point. The covariance function defines how smooth the function mapping neighboring points are. You can use a number of well characterised functions as the covariance function or you can use a neural network to learn complex connections. 

The omniplate python package developed by the Swain lab uses a Gaussian process with an infinitely differentiable covariance functions. The enables the time series protein florescence data to be model, then doubly differentiated to find the point of max increase in florescence. It is important to use a similar time point to compare all the different constructs at and the time of max growth rate is appropriate. Partly because it is simple to calculate whilst making sure all the constructs are being compared at a similar point in the growth cycle (mid exponential). It also important to account for auto-fluorescence and the size of cells in various media in order to remove confounding contributions to sample fluorescence.

\section{Bayesian Statistical Models}

To be able to compare samples across RNA-seq runs users need to be able to remove biases that changes from run to run. For example, the amplificaition of reads from each lane of a RNA-seq machine varies significantly. Therefore direct comparison of transcript counts mapped to a genome will, for the most part, depend on the total reads read by that lane of the RNA-seq machine.  Other amplification biases can be introduced, the shotgun method of short read sequencing means the number of reads per gene will be proportional to the length of that gene. Simply because longer genes can be separated into more fragments. In addition elongation biases between the nucleotides can change the amplificiation ratio of genes. Certein gene with high GC content may not be amplified as well because they bind too tightly for the melting stage to occur efficiently. 

Raw reads are rarely used as the measure of expression between samples and between genes. Instead, they are normalised either by internal methods or by external controls such as spike-in samples. Internal normalisation commonly consists of converting raw reads into transcripts per million or reads per million. It can been widely reported at the read per million method has significant biases and should not be used. However, transcripts per million account for the total read variation between runs and the gene length biases. However, dividing by total reads does leave TPM counts vunerable to being dominated by the behaviour of a few highly expressed genes. Since there is a large order of magnitude between expression across an organisms genome, gene that are expressed on the order of $10^4$ transcripts per cell will contribute more to the total reads compared to transcript that only occur once or twice. If the experiments significant change the expression of the highly expressing genes but the users is mostly interested in the behavour of the lowly expressing genes, comparing TPM may confound expression patterns. Neither method attempts to deal with GC biases. Alternatively, an external control of known volumes of synthetic RNA can be introduced with differing GC content and lengths. The comparison of these RNA levels after being amplified in the RNA-seq assay can discover biases in transcript length, total read and GC content. A rigorous method for using this information to normal counts across the genome has not be developed as error in spike-in volumes are very common and obscure predictions expected reads post-sequencing.

\section{Experimental assays}
I did not conduct any of the experimental assays discussed in this thesis. However, I did contribute to the planning of the qPCR, platereader and RNA-seq assays conducted in the lab. I briefly outline their protocols here for completion. More detailed descriptions are available in the published article.

\bibliographystyle{apalike}
\bibliography{sbc-template}

\end{document}